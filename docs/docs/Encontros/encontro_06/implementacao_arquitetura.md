---
sidebar_position: 5
title: Implementando Arquitetura
---

import useBaseUrl from '@docusaurus/useBaseUrl';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Implementando Arquitetura de Microsservi√ßos

Pessoas lindas do meu cora√ß√£o, aqui vamos gastar a ponta dos nossos dedos (ok exagerei mas foi para deixar tudo mais dram√°tico) !!

Vamos implementar algumas arquiteturas de microsservi√ßos, conforme os conceitos que discultimos anteriormente.

Nossa primeira arquitetura j√° est√° vindo!

:::warning[AGORA MUUUUITO S√âRIO, PRATIQUEM!]

Pessoal eu vou tentar ao m√°ximo descrever todos os passos para realizarmos a implementa√ß√£o de diversas arquiteturas e servi√ßos e padr√µes com voc√™s. Mas, eu apenas estou garantindo para voc√™s, se voc√™s n√£o praticarem, n√£o vai adiantar de nada.

<img src="https://external-preview.redd.it/eKcRAzHsHicyHykAqSJCpju139qFIRiPJt4v25TtMXA.jpg?auto=webp&s=6e59d055d1153e423a6c1735ebaa2d7c38a9c58b" style={{ display: 'block', marginLeft: 'auto', maxHeight: '65vh', marginRight: 'auto', marginBottom: '24px' }}/>


:::

---

## Arquitetura 01 - Comunica√ß√£o Ass√≠ncrona com RabbitMQ

Pessoal, para iniciarmos nosso estudo, vamos implementar um sistema como descrito na imagem abaixo:

<img src={useBaseUrl("/img/microsservicos/arquitetura_01.png")} style={{ display: 'block', marginLeft: 'auto', maxHeight: '65vh', marginRight: 'auto', marginBottom: '24px' }}/>

O que est√° acontecendo aqui:

- Temos um `gateway`, implementado com o ***Nginx***, que recebe as requisi√ß√µes HTTP externa e as encaminha para o servi√ßo adequado.
- Temos o nosso `Service01`, que √© respons√°vel por receber as requisi√ß√µes do `gateway` e encaminhar para o `RabbitMQ`. Ele recebe requisi√ß√µes do tipo `POST` e envia para o `RabbitMQ` a data e hora que a requisi√ß√£o ocorreu. Ele disponibiliza um endpoint `/ping` que recebe as requisi√ß√µes.
- Temos o nosso `Service02`, que √© respons√°vel por receber as mensagens do `RabbitMQ` e armazenar em um banco de dados em mem√≥ria (isso mesmo √© s√≥ uma lista de objetos em mem√≥ria). Ele disponibiliza um endpoint `/pong` que recebe as requisi√ß√µes do tipo `GET` para retornar a lista de mensagens armazenadas.
- Por fim, temos nosso broker de mensagens, o `RabbitMQ`, que √© respons√°vel por receber as mensagens do `Service01` e encaminhar para o `Service02`.

### Verificando os requisitos

Legal, agora que falamos como nossa arquitetura funciona, vamos verificar os requisitos para implementar ela:

- [ ] Ter o ***Nginx*** instalado e configurado para encaminhar as requisi√ß√µes para o `Service01` e para o `Service02`.
- [ ] Ter o ***RabbitMQ*** instalado e configurado para receber as mensagens do `Service01` e encaminhar para o `Service02`.
- [ ] Ter o `Service01` implementado para receber as requisi√ß√µes do `gateway` e encaminhar para o `RabbitMQ`.
- [ ] Ter o `Service02` implementado para receber as mensagens do `RabbitMQ` e armazenar em um banco de dados em mem√≥ria.

Assim que tivermos todo o nosso ***checklist*** preenchido, vamos ter nosso sistema funcionando üê®üê≥!!

Pensado de forma pedag√≥gica, seria mais interessante colocarmos esses passos em ordem. Masssss, vamos utilizar a premissa de que o time deve escolher o que vai priorizar para implementar primeiro! Logo, vamos criar um diret√≥rio para que os arquivos de nossa solu√ß√£o possam ser organizados.

A minha sugest√£o de diret√≥rios seria:

```bash
microsservicos/
‚îú‚îÄ‚îÄ Service01/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Service02/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf
‚îú‚îÄ‚îÄ rabbitmq/
‚îú‚îÄ‚îÄ docker-compose.yml
```

:::tip[Calma, calma, calma!]

N√£o precisamos j√° criar toda nossa estrutura de arquivos. Vamos implementando conforme vamos avan√ßando. Mas, √© sempre bom ter uma ideia de como vamos organizar nossos arquivos.

:::

### Adicionando o Service01 e o docker-compose

Vamos iniciar implementando o nosso `Service01`, o `RabbitMQ` e o docker-compose que vai ligar esses dois. Como s√≥ temos parte da nossa estrutura, vamos ver como ficou nossa estrutura de pastas:

```bash
microsservicos/
‚îú‚îÄ‚îÄ Service01/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ rabbitmq/
‚îÇ   ‚îú‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env
```

> Calma l√° Murilo, tem arquivos novos ai p√¥!

Sim, sim, sim! Vamos criar um arquivo `.env` dentro da pasta `Service01` para armazenar as vari√°veis de ambiente que vamos utilizar em nosso servi√ßo. Por que vamos fazer isso? Voc√™ pode se perguntar. Com as nossas vari√°veis de ambiente armazenadas em um arquivo `.env`, podemos utilizar o `docker-compose` para passar essas vari√°veis para o nosso container. Assim, n√£o precisamos ficar alterando o c√≥digo toda vez que precisamos mudar uma vari√°vel de ambiente.

Vamos escrever primeiro nosso servi√ßo `Service01`. Ele √© uma aplica√ß√£o que utilizar o Flask e o Uvicorn como depend√™ncias. Vamos criar o arquivo `app.py` dentro da pasta `Service01` com o seguinte conte√∫do:

```python
# Service01/app.py

from fastapi import FastAPI
from pydantic import BaseModel
from datetime import datetime
app = FastAPI()

class Message(BaseModel):
    date: datetime = None
    msg: str

messages = []

@app.post("/ping")
async def ping(msg: Message):
    msg.date=datetime.now()
    return {"message": f"Created at {msg.date}", "content": f"{msg.msg}"}

# Executa a aplica√ß√£o com a informa√ß√£o de HOST e PORTA enviados por argumentos
if __name__ == "__main__":
    import uvicorn
    import os
    print(os.environ)
    if "SERVICE_01_HOST" in os.environ and "SERVICE_01_PORT" in os.environ:
        uvicorn.run(app, host=os.environ["SERVICE_01_HOST"], port=os.environ["SERVICE_01_PORT"])
    else:
        raise Exception("HOST and PORT must be defined in environment variables")

```

Agora, vamos criar o arquivo `Dockerfile` dentro da pasta `Service01` com o seguinte conte√∫do:

```Dockerfile
# Service01/Dockerfile

FROM python:3.8-slim

WORKDIR /app

COPY requirements.txt requirements.txt

RUN pip install -r requirements.txt

COPY . .

CMD ["python", "app.py"]
```

Por fim, vamos criar o arquivo `requirements.txt` dentro da pasta `Service01` com o seguinte conte√∫do:

```txt
fastapi==0.68.1
uvicorn==0.15.0
```

Agora, vamos criar o arquivo `docker-compose.yml` na raiz do nosso projeto. Aqui teremos algumas diferen√ßas, dentre elas, a utiliza√ß√£o dos dados presentes no arquivo `.env` para passar as vari√°veis de ambiente para o nosso container. Vamos criar o arquivo `docker-compose.yml` com o seguinte conte√∫do:

```yaml
# docker-compose.yml

version: '3.8'

services:
  service01:
    build:
      context: ./Service01
    ports:
      - "${SERVICE01_HOST_PORT}:${SERVICE_01_PORT}"
    environment:
      - SERVICE_01_HOST=${SERVICE_01_HOST}
      - SERVICE_01_PORT=${SERVICE_01_PORT}

```

Por fim, vamos criar o arquivo `.env` dentro da pasta `Service01` com o seguinte conte√∫do:

```env
SERVICE_01_HOST=0.0.0.0
SERVICE_01_PORT=8001
SERVICE01_HOST_PORT=8000
```

> Murilo, eita n√≥is, tem muita coisa nova ai!

<img src="https://pbs.twimg.com/media/Ei8Gep-XYAADnPO.jpg" style={{ display: 'block', marginLeft: 'auto', maxHeight: '65vh', marginRight: 'auto', marginBottom: '24px' }}/>

Calma, calma, calma! Vamos entender o que fizemos:

- Arquivo `app.py`:
    - Criamos uma aplica√ß√£o `FastAPI` que possui um endpoint `/ping` que recebe uma mensagem e retorna a data e hora que a mensagem foi recebida.
    - Utilizamos o `pydantic` para definir o modelo da mensagem que ser√° recebida. Assim, podemos definir qual o formato da mensagem que ser√° recebida. Se o JSON enviado n√£o estiver no formato esperado, o `FastAPI` retorna um erro.
    - Para receber as vari√°veis de ambiente `SERVICE_01_HOST` e `SERVICE_01_PORT`, utilizamos a biblioteca `os`. Com o `os.environ`, conseguimos acessar as vari√°veis de ambiente do sistema operacional. No nosso caso, as vari√°veis de ambiente s√£o passadas pelo `docker-compose` e ficam acess√≠veis para a aplica√ß√£o.
    - Utilizamos o `uvicorn` para executar a aplica√ß√£o. O `uvicorn` √© um servidor ASGI que permite executar aplica√ß√µes `FastAPI`.

- Arquivo `Dockerfile`:
    - Utilizamos a imagem `python:3.8-slim` como base para a nossa aplica√ß√£o. Essa imagem j√° possui o Python 3.8 instalado e √© uma vers√£o mais leve da imagem `python:3.8`.
    - Definimos o diret√≥rio de trabalho como `/app`.
    - Copiamos o arquivo `requirements.txt` para o diret√≥rio `/app`.
    - Instalamos as depend√™ncias do arquivo `requirements.txt` com o comando `pip install -r requirements.txt`.
    - Copiamos todos os arquivos do diret√≥rio atual para o diret√≥rio `/app`.
    - Definimos o comando que ser√° executado quando o container for iniciado. Neste caso, executamos o arquivo `app.py`.

- Arquivo `.env`:
    - Definimos as vari√°veis de ambiente `SERVICE_01_HOST`, `SERVICE_01_PORT` e `SERVICE01_HOST_PORT`. Essas vari√°veis de ambiente s√£o utilizadas para definir o host, a porta e a porta de exposi√ß√£o do servi√ßo `Service01`.

- Arquivo `docker-compose.yml`:
    - Definimos a vers√£o do `docker-compose` como `3.8`.
    - Criamos um servi√ßo chamado `service01` que utiliza o `Dockerfile` presente no diret√≥rio `Service01` para construir a imagem do servi√ßo.
    - Mapeamos a porta `${SERVICE01_HOST_PORT}` do host para a porta `${SERVICE_01_PORT}` do container. Assim, podemos acessar o servi√ßo `Service01` na porta definida em `SERVICE01_HOST_PORT`.
    - Passamos as vari√°veis de ambiente `SERVICE_01_HOST` e `SERVICE_01_PORT` para o container. Essas vari√°veis de ambiente s√£o definidas no arquivo `.env` e s√£o utilizadas pela aplica√ß√£o `Service01`.

Pessoal, voc√™s vir√£o a beleza desse processo? Se n√≥s alterarmos o nosso arquivo `.env`, n√£o precisamos alterar o nosso c√≥digo. Isso √© muito legal, pois podemos alterar as vari√°veis de ambiente sem precisar alterar o c√≥digo da aplica√ß√£o. Isso facilita a configura√ß√£o e o gerenciamento das vari√°veis de ambiente.

<img src="https://i.gifer.com/A5OX.gif" style={{ display: 'block', marginLeft: 'auto', maxHeight: '65vh', marginRight: 'auto', marginBottom: '24px' }}/>

:::danger[Cuidado com apenas o resultado pronto]

Pessoal eu queria muito dizer para voc√™s que foi super f√°cil, sem problemas, que passar mantega no p√£o foi mais dificil. Mas, ao menos para mim, n√£o foi assim que eu implementei esses passos. Eu tive que pesquisar, errar, testar, errar, corrigir, errar, errar, erarrr, errrarrrr e at√© que enfim conseguir implementar a solu√ß√£o da maneira que eu gostaria de apresentar para voc√™s.

Ent√£o, n√£o se preocupem se voc√™s n√£o conseguirem implementar de primeira. O importante √© tentar, errar, corrigir e tentar de novo. A pr√°tica leva a perfei√ß√£o. As 32x que eu tive que remover a imagem desse Service01 que o digam.

:::

Beleza, mas agora vamos l√°, ainda n√£o devemos comemorar!! Faltam muitas coisas aqui para terminarmos nosso primeiro passo! Vamos adicionar o RabbitMQ nessa brincadeira!

### Adicionando o RabbitMQ

Vamos utilizar a imagem oficial do RabbitMQ, dispon√≠vel no [DockerHub](https://hub.docker.com/_/rabbitmq). Essa imagem vai ser adicionada no nosso arquivo `docker-compose.yml` para que o `docker-compose` possa baixar e executar o RabbitMQ. Al√©m disso, vamos configurar dentro do nosso arquivo de `.env` uma vari√°vel para definir o nosso usu√°rio e a senha do RabbitMQ.

Vamos adicionar as vari√°veis de ambiente no arquivo `.env`:

```env
# Configura√ß√µes do Service01

SERVICE_01_HOST=0.0.0.0
SERVICE_01_PORT=8001
SERVICE01_HOST_PORT=8000

# Configurando o RabbitMQ

RABBITMQ_DEFAULT_USER=inteli
RABBITMQ_DEFAULT_PASS=inteli_secret
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_QUEUE=mensagens_async
```

Agora vamos adicionar o servi√ßo do RabbitMQ no nosso arquivo `docker-compose.yml`:

```yaml
# docker-compose.yml

version: '3.8'

services:
  service01:
    build:
      context: ./Service01
    ports:
      - "${SERVICE01_HOST_PORT}:${SERVICE_01_PORT}"
    env_file:
      - .env
    depends_on:
      - rabbitmq

  rabbitmq:
    image: rabbitmq:3.12.14-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS}
```

Quando utilizamos a vers√£o `management-alpine` da imagem do RabbitMQ, temos acesso a uma interface web que nos permite visualizar as filas, as trocas e os usu√°rios do RabbitMQ. Essa interface √© muito √∫til para debugar e monitorar o RabbitMQ. Para acessar a interface web, basta acessar o endere√ßo [`http://localhost:15672`](http://localhost:15672/) no navegador e informar o usu√°rio e a senha configurados no arquivo `.env`.

Pessoal reparem que adicionamos a vari√°vel `depends_on` no servi√ßo `service01`. Essa vari√°vel indica que o servi√ßo `service01` depende do servi√ßo `rabbitmq`. Com isso, o `docker-compose` garante que o servi√ßo `rabbitmq` seja iniciado antes do servi√ßo `service01`. Isso √© importante, pois o `service01` precisa do `rabbitmq` para enviar as mensagens.

Outro ponto importante, o `env_file` no servi√ßo `service01` indica que as vari√°veis de ambiente do arquivo `.env` ser√£o passadas para o container do servi√ßo `service01`. Assim, as vari√°veis de ambiente definidas no arquivo `.env` ficam acess√≠veis para a aplica√ß√£o `Service01`.

E boa!!! Temos nosso RabbitMQ funcionando, mas ainda n√£o temos a comunica√ß√£o entre o Service01 e o RabbitMQ. Vamos implementar essa comunica√ß√£o agora!

### Comunica√ß√£o entre Service01 e RabbitMQ

Para enviar mensagens para o RabbitMQ, vamos utilizar a biblioteca `pika`. Essa biblioteca √© uma implementa√ß√£o do protocolo AMQP (Advanced Message Queuing Protocol) para Python. Com o `pika`, podemos enviar e receber mensagens do RabbitMQ de forma ass√≠ncrona. Mais informa√ß√µes sobre a biblioteca, podemos acessar a [documenta√ß√£o oficial](https://pika.readthedocs.io/en/stable/).

Para isso, vamos ter que fazer algumas modifica√ß√µes no nosso arquivo `app.py` do `Service01`. Vamos adicionar a comunica√ß√£o com o RabbitMQ para enviar as mensagens recebidas no endpoint `/ping`. Vamos modificar tamb√©m o arquivo `requirements.txt` para adicionar a depend√™ncia do `pika`.

```txt
fastapi==0.68.1
uvicorn==0.15.0
pika==1.2.0
```

:::danger[Mudan√ßa na estrutura da imagem]

Pessoal, aqui chegamos em um ponto importante. N√≥s vamos ter que modificar a estrutura da nossa imagem do `Service01` para que ele consiga se comunicar com o RabbitMQ. Vamos adicionar a comunica√ß√£o com o RabbitMQ no arquivo `app.py`. Vamos precisar informar que o docker precisa reconstruir a imagem do `Service01` para que ele possa adicionar a depend√™ncia do `pika`.

Vamos excluir nossas imagens  Excluir nossa imagem antiga e criar uma nova imagem com o comando `docker-compose up --build`.


:::

Vamos modificar o arquivo `app.py` do `Service01` para adicionar a comunica√ß√£o com o RabbitMQ:

```python

# Service01/app.py

# Adicionando a funcionalidade de enviar mensagens com data e hora para o broker do RabbitMQ

from fastapi import FastAPI
from pydantic import BaseModel
from datetime import datetime
import pika

app = FastAPI()

class Message(BaseModel):
    date: datetime = None
    msg: str

# Cria uma fun√ß√£o que faz o envio das mensagens para o RabbitMQ
def send_message_rabbitmq(msg: Message):
    # Verifica se as vari√°veis de ambiente est√£o definidas
    if "RABBITMQ_HOST" not in os.environ or "RABBITMQ_PORT" not in os.environ:
        raise Exception("RABBITMQ_HOST and RABBITMQ_PORT must be defined in environment variables")

    credentials = pika.PlainCredentials(os.environ["RABBITMQ_DEFAULT_USER"], os.environ["RABBITMQ_DEFAULT_PASS"])
    connection = pika.BlockingConnection(pika.ConnectionParameters(
        os.environ["RABBITMQ_HOST"]
        , os.environ["RABBITMQ_PORT"]
        , '/'
        , credentials))
    channel = connection.channel()
    channel.queue_declare(queue=os.environ["RABBITMQ_QUEUE"])
    channel.basic_publish(exchange='', routing_key=os.environ["RABBITMQ_QUEUE"], body=f"{msg.date} - {msg.msg}")
    connection.close()

@app.post("/ping")
async def ping(msg: Message):
    msg.date=datetime.now()
    send_message_rabbitmq(msg)
    return {"message": f"Created at {msg.date}", "content": f"{msg.msg}"}

# Executa a aplica√ß√£o com a informa√ß√£o de HOST e PORTA enviados por argumentos
if __name__ == "__main__":
    import uvicorn
    import os
    print(os.environ)
    if "SERVICE_01_HOST" in os.environ and "SERVICE_01_PORT" in os.environ:
        uvicorn.run(app, host=os.environ["SERVICE_01_HOST"], port=os.environ["SERVICE_01_PORT"])
    else:
        raise Exception("HOST and PORT must be defined in environment variables")

```

E pronto, agora temos nosso `Service01` enviando mensagens para o RabbitMQ. Vamos testar se a comunica√ß√£o est√° funcionando corretamente. Para isso, vamos iniciar o RabbitMQ e o Service01 com o comando `docker-compose up`. Em seguida, vamos acessar o endpoint `/ping` do Service01 para enviar uma mensagem para o RabbitMQ.

Estamos avan√ßando!! Como est√° nosso estado atual:

- [ ] Ter o ***Nginx*** instalado e configurado para encaminhar as requisi√ß√µes para o `Service01` e para o `Service02`.
- [x] Ter o ***RabbitMQ*** instalado e configurado para receber as mensagens do `Service01` e encaminhar para o `Service02`.
- [x] Ter o `Service01` implementado para receber as requisi√ß√µes do `gateway` e encaminhar para o `RabbitMQ`.
- [ ] Ter o `Service02` implementado para receber as mensagens do `RabbitMQ` e armazenar em um banco de dados em mem√≥ria.

Vamos agora configurar o `Service02` para receber as mensagens do RabbitMQ e armazenar em um banco de dados em mem√≥ria.

### Adicionando o Service02

Agora vamos construir nosso segundo servi√ßo. Vamos criar a estrutura de pastas para o `Service02` e adicionar o arquivo `app.py`. Os arquivos `Dockerfile` e `requirements.txt` ser√£o os mesmos do `Service01`. Vamos criar o arquivo `app.py` dentro da pasta `Service02` com o seguinte conte√∫do:

```python
# Servi√ßo 2 - recebe as mensagens via RabbitMQ e as armazena em um banco de dados em mem√≥ria

from fastapi import FastAPI
from pydantic import BaseModel
from datetime import datetime
import pika
import os

app = FastAPI()
banco_em_memoria = []

class Message(BaseModel):
    date: datetime = None
    msg: str

# Cria uma fun√ß√£o que recebe as mensagens para o RabbitMQ
def receive_message_rabbitmq():
    # Verifica se as vari√°veis de ambiente est√£o definidas
    if "RABBITMQ_HOST" not in os.environ or "RABBITMQ_PORT" not in os.environ:
        raise Exception("RABBITMQ_HOST and RABBITMQ_PORT must be defined in environment variables")

    credentials = pika.PlainCredentials(os.environ["RABBITMQ_DEFAULT_USER"], os.environ["RABBITMQ_DEFAULT_PASS"])
    connection = pika.BlockingConnection(pika.ConnectionParameters(
        os.environ["RABBITMQ_HOST"]
        , os.environ["RABBITMQ_PORT"]
        , '/'
        , credentials))
    channel = connection.channel()
    channel.queue_declare(queue=os.environ["RABBITMQ_QUEUE"], durable=True)
    channel.basic_consume(queue=os.environ["RABBITMQ_QUEUE"], on_message_callback=callback, auto_ack=True)
    channel.start_consuming()

def callback(ch, method, properties, body):
    print(f" [x] Received {body}")
    banco_em_memoria.append(body)

@app.get("/messages")
async def get_messages():
    return banco_em_memoria

# Executa a aplica√ß√£o com a informa√ß√£o de HOST e PORTA enviados por argumentos
if __name__ == "__main__":
    import uvicorn
    import os
    print(os.environ)
    if "SERVICE_02_HOST" in os.environ and "SERVICE_02_PORT" in os.environ:
        receive_message_rabbitmq()
        uvicorn.run(app, host=os.environ["SERVICE_02_HOST"], port=os.environ["SERVICE_02_PORT"])
    else:
        raise Exception("HOST and PORT must be defined in environment variables")

```

Agora vamos compreender o que est√° acontecendo aqui:

- Criamos uma aplica√ß√£o `FastAPI` que possui um endpoint `/messages` que retorna a lista de mensagens armazenadas em um banco de dados em mem√≥ria.
- Criamos uma lista `banco_em_memoria` que armazena as mensagens recebidas do RabbitMQ.
- Criamos uma fun√ß√£o `receive_message_rabbitmq` que recebe as mensagens do RabbitMQ e armazena no banco de dados em mem√≥ria.
- Criamos uma fun√ß√£o `callback` que √© chamada quando uma mensagem √© recebida do RabbitMQ. Essa fun√ß√£o adiciona a mensagem no banco de dados em mem√≥ria.
- Criamos um endpoint `/messages` que retorna a lista de mensagens armazenadas no banco de dados em mem√≥ria.

Agora vamos ajustar o arquivo `.env` para adicionar as vari√°veis de ambiente do `Service02`:

```env
# Configura√ß√µes do Service01

SERVICE_01_HOST=0.0.0.0
SERVICE_01_PORT=8001
SERVICE01_HOST_PORT=8000

# Configurando o RabbitMQ

RABBITMQ_DEFAULT_USER=inteli
RABBITMQ_DEFAULT_PASS=inteli_secret
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_QUEUE=mensagens_async

# Configura√ß√µes do Service02

SERVICE_02_HOST=0.0.0.0
SERVICE_02_PORT=8000
SERVICE02_HOST_PORT=8002
```

Agora vamos adicionar o servi√ßo `service02` no nosso arquivo `docker-compose.yml`:

```yaml
# docker-compose.yml

version: '3.8'

services:
  service01:
    build:
      context: ./Service01
    ports:
      - "${SERVICE01_HOST_PORT}:${SERVICE_01_PORT}"
    env_file:
      - .env
    depends_on:
      - rabbitmq

  rabbitmq:
    image: rabbitmq:3.12.14-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS}

  service02:
    build:
      context: ./Service02
    ports:
      - "${SERVICE02_HOST_PORT}:${SERVICE_02_PORT}"
    env_file:
      - .env
    depends_on:
      - rabbitmq
```

Pronto, agora temos o nosso `Service02` implementado e configurado no `docker-compose`. Vamos testar se a comunica√ß√£o entre o `Service01` e o `Service02` est√° funcionando corretamente. Para isso, vamos iniciar o RabbitMQ, o Service01 e o Service02 com o comando `docker-compose up`. Em seguida, vamos acessar o endpoint `/ping` do Service01 para enviar uma mensagem para o RabbitMQ. Por fim, vamos acessar o endpoint `/messages` do Service02 para verificar se a mensagem foi armazenada corretamente.

Espera um pouco, temos um problema aqui. O `Service02` n√£o est√° recebendo as mensagens do RabbitMQ. Isso ocorre porque o `Service02` n√£o est√° executando a fun√ß√£o `receive_message_rabbitmq`. Para corrigir isso, vamos modificar o arquivo `app.py` do `Service02` para executar a fun√ß√£o `receive_message_rabbitmq` quando o servi√ßo for iniciado.

Massss antes de continuarmos, vamos entender o que est√° acontecendo. A biblioteca `pika` √© uma biblioteca s√≠ncrona, ou seja, ela bloqueia a execu√ß√£o do programa enquanto aguarda a chegada de mensagens. Para resolver esse problema, precisamos utilizar algum recurso que permita a execu√ß√£o da fun√ß√£o `receive_message_rabbitmq` em ***PARALELO*** com a execu√ß√£o da aplica√ß√£o. Eles precisam compartilhar o mesmo contexto de execu√ß√£o, mas precisam ser executados em ***PARALELO***.

Mesmo processo, execu√ß√£o em paralelo, lembra algo? Em especial algo que falamos que se inicia com a letra ***T***. Sim, sim, sim, ***THREADS***. Vamos utilizar ***THREADS*** para executar a fun√ß√£o `receive_message_rabbitmq` em ***PARALELO*** com a execu√ß√£o da aplica√ß√£o.

Vamos alterar o c√≥digo do nosso `Service02` para adicionar a execu√ß√£o da fun√ß√£o `receive_message_rabbitmq` em ***THREADS***:

```python
# Servi√ßo 2 - recebe as mensagens via RabbitMQ e as armazena em um banco de dados em mem√≥ria

from fastapi import FastAPI
from pydantic import BaseModel
from datetime import datetime
import threading
import pika
import os
# Ajuste para tentar reconectar ao RabbitMQ
from pika.connection import Parameters
Parameters.DEFAULT_CONNECTION_ATTEMPTS = 10



app = FastAPI()
banco_em_memoria = []

class Message(BaseModel):
    date: datetime = None
    msg: str

# Fun√ß√£o de callback utilizada
def callback(ch, method, properties, body):
    print(f" [x] Received {body}")
    banco_em_memoria.append(body)

# Cria uma fun√ß√£o que recebe as mensagens para o RabbitMQ
def receive_message_rabbitmq():
    # Verifica se as vari√°veis de ambiente est√£o definidas
    if "RABBITMQ_HOST" not in os.environ or "RABBITMQ_PORT" not in os.environ:
        raise Exception("RABBITMQ_HOST and RABBITMQ_PORT must be defined in environment variables")

    credentials = pika.PlainCredentials(os.environ["RABBITMQ_DEFAULT_USER"], os.environ["RABBITMQ_DEFAULT_PASS"])
    connection = pika.BlockingConnection(pika.ConnectionParameters(
        os.environ["RABBITMQ_HOST"]
        , os.environ["RABBITMQ_PORT"]
        , '/'
        , credentials))
    channel = connection.channel()
    channel.queue_declare(queue=os.environ["RABBITMQ_QUEUE"])
    channel.basic_consume(queue=os.environ["RABBITMQ_QUEUE"], on_message_callback=callback)
    channel.start_consuming()


@app.get("/messages")
async def get_messages():
    return banco_em_memoria

# Executa a aplica√ß√£o com a informa√ß√£o de HOST e PORTA enviados por argumentos
if __name__ == "__main__":
    import uvicorn
    import os
    print(os.environ)
    if "SERVICE_02_HOST" in os.environ and "SERVICE_02_PORT" in os.environ:
        try:    
            # Cria uma thread para receber as mensagens do RabbitMQ
            thread = threading.Thread(target=receive_message_rabbitmq)
            thread.start()
            uvicorn.run(app, host=os.environ["SERVICE_02_HOST"], port=os.environ["SERVICE_02_PORT"])
        except Exception as e:
            print(f"Finalizando a execu√ß√£o da thread: {e}")
            thread.stop()
    else:
        raise Exception("HOST and PORT must be defined in environment variables")


```

Pessoal agora sim, temos o nosso `Service02` recebendo as mensagens do RabbitMQ e armazenando em um banco de dados em mem√≥ria. Vamos testar se a comunica√ß√£o entre o `Service01` e o `Service02` est√° funcionando corretamente. Para isso, vamos iniciar o RabbitMQ, o Service01 e o Service02 com o comando `docker-compose up`. Em seguida, vamos acessar o endpoint `/ping` do Service01 para enviar uma mensagem para o RabbitMQ. Por fim, vamos acessar o endpoint `/messages` do Service02 para verificar se a mensagem foi armazenada corretamente.

Aeeee temos quase tudo completo agora:

- [ ] Ter o ***Nginx*** instalado e configurado para encaminhar as requisi√ß√µes para o `Service01` e para o `Service02`.
- [x] Ter o ***RabbitMQ*** instalado e configurado para receber as mensagens do `Service01` e encaminhar para o `Service02`.
- [x] Ter o `Service01` implementado para receber as requisi√ß√µes do `gateway` e encaminhar para o `RabbitMQ`.
- [x] Ter o `Service02` implementado para receber as mensagens do `RabbitMQ` e armazenar em um banco de dados em mem√≥ria.

Vamos l√° pessoal s√≥ mais um pouco!!
Vamos adicionar o ***Nginx*** para encaminhar as requisi√ß√µes para o `Service01` e para o `Service02`.

### Adicionando o Nginx

Vamos utilizar a imagem oficial do Nginx, dispon√≠vel no [DockerHub](https://hub.docker.com/_/nginx). Essa imagem vai ser adicionada no nosso arquivo `docker-compose.yml` para que o `docker-compose` possa baixar e executar o Nginx. Al√©m disso, vamos configurar o Nginx para encaminhar as requisi√ß√µes para o `Service01` e para o `Service02`.

Primeiro vamos ajustar nosso arquivo de `nginx.conf` para configurar o Nginx para encaminhar as requisi√ß√µes para o `Service01` e para o `Service02`. Vamos criar o arquivo `nginx.conf` dentro da pasta `nginx` com o seguinte conte√∫do:

```nginx
# gateway/nginx.conf

worker_processes 1;

events { worker_connections 1024; }

http {
    sendfile on;

    upstream Service01 {
        server Service01:8001;
    }

    upstream Service02 {
        server Service02:8002;
    }


    server {
        listen 80;

        location /ping {
            proxy_pass http://Service01;
        }

        location /messages {
            proxy_pass http://Service02;
        }

    }
}
```

Observem o que est√° acontecendo aqui:

- Definimos o n√∫mero de processos do Nginx como 1.
- Definimos o n√∫mero de conex√µes por processo como 1024.
- Configuramos o Nginx para encaminhar as requisi√ß√µes para o `Service01` na porta 8001.
- Configuramos o Nginx para encaminhar as requisi√ß√µes para o `Service02` na porta 8002.
- Criamos um servidor que escuta na porta 80.
- Configuramos o Nginx para encaminhar as requisi√ß√µes para o `Service01` no endpoint `/ping`.
- Configuramos o Nginx para encaminhar as requisi√ß√µes para o `Service02` no endpoint `/messages`.

Agora vamos ajustar o arquivo `docker-compose.yml` para adicionar o servi√ßo `nginx`:

```yaml
# docker-compose.yml

version: '3.8'

services:
  service01:
    build:
      context: ./Service01
    ports:
      - "${SERVICE01_HOST_PORT}:${SERVICE_01_PORT}"
    env_file:
      - .env
    depends_on:
      - rabbitmq


  rabbitmq:
    image: rabbitmq:3.12.14-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS}


  service02:
    build:
      context: ./Service02
    ports:
      - "${SERVICE02_HOST_PORT}:${SERVICE_02_PORT}"
    env_file:
      - .env
    depends_on:
      - rabbitmq
    restart: on-failure

  gateway:
    build: ./nginx
    ports:
      - "8000:80"
```

Agora pessoal, para subir nossa aplica√ß√£o, vamos executar o comando `docker-compose up`. Em seguida, vamos acessar o endpoint `/ping` do Nginx para enviar uma mensagem para o RabbitMQ. Por fim, vamos acessar o endpoint `/messages` do Nginx para verificar se a mensagem foi armazenada corretamente.

Enfim!!! Temos nosso sistema funcionando üê®üê≥!! Parab√©ns a todos que chegaram at√© aqui. Agora, vamos comemorar e descansar um pouco.

Pessoal, eu queria muito me vangloriar e dizer que n√≥s estudamos o comportamento das Threads para utilizar exatamente aqui, quando precisamos delas. Contudo, eu n√£o fiz isso de forma proposital. 

Contudo, queria chamar a aten√ß√£o de voc√™s para a import√¢ncia de compreender alguns comportamentos e conceitos que s√£o base para a constru√ß√£o das nossas solu√ß√µes. A utiliza√ß√£o de Threads √© um desses conceitos que s√£o muito importantes para a constru√ß√£o de sistemas distribu√≠dos e escal√°veis. Ent√£o, n√£o deixem de estudar e compreender esses conceitos, pois eles s√£o fundamentais para a constru√ß√£o de sistemas robustos e escal√°veis.

Gostaria de deixar como pensamento final para voc√™s:

```quote
‚ÄúA wildfire destroys everything in its path. 
It will be the same with your powers unless you learn to control them.‚Äù 
‚Äî Giovanni
```

<img src="https://blogger.googleusercontent.com/img/a/AVvXsEgd6-b9tfTF0rXsofi5GG4f2nJvkZyWijBxKtTA8bSxOHNjgPY-vH3TsSSPKP-iRlrEOz2N_penVxMN0s7ImUTPEJ9D9ivnUnvpfzu4fAYZ-iLZvO4E2_IESZ4rodtgIKnCIlHovso7vtsCYup_4RHPWnTlMASK5XWNL9j3YNw3nJNpXLptdrpC7WpD=w1600" style={{ display: 'block', marginLeft: 'auto', maxHeight: '65vh', marginRight: 'auto', marginBottom: '24px' }}/>
